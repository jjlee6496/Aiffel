{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad001946",
      "metadata": {
        "id": "ad001946"
      },
      "source": [
        "# 프로젝트 (1) load_digits : 손글씨를 분류해 봅시다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24286f6e",
      "metadata": {
        "id": "24286f6e"
      },
      "source": [
        "## (1) 필요한 모듈 import하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9329bfda",
      "metadata": {
        "id": "9329bfda"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b61b709e",
      "metadata": {
        "id": "b61b709e"
      },
      "source": [
        "## (2) 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f0cb1a",
      "metadata": {
        "id": "c1f0cb1a"
      },
      "outputs": [],
      "source": [
        "digits = load_digits()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a14e353",
      "metadata": {
        "id": "2a14e353"
      },
      "source": [
        "## (3) 데이터 이해하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8a06d1b",
      "metadata": {
        "id": "b8a06d1b",
        "outputId": "37c11733-468d-46e2-dfcf-4d621d82a5fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29089400",
      "metadata": {
        "id": "29089400",
        "outputId": "633ce787-832b-401e-ecbe-5e84ccfadea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits_data = digits.data\n",
        "digits_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bad6ef5",
      "metadata": {
        "id": "5bad6ef5",
        "outputId": "555dc238-cb83-4238-997d-8d18680ec301"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64,)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits_data[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436d5741",
      "metadata": {
        "id": "436d5741",
        "outputId": "6abc4e82-8bc6-48cd-ff28-36d5b38c876e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "# 브라우저에서 바로 그림을 볼 수 있게 해주는 역할을 합니다 \n",
        "\n",
        "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c8c3e21",
      "metadata": {
        "id": "5c8c3e21",
        "outputId": "0729a4f1-8d3f-4f1d-ab7c-88f3c3a31189"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1) # 10개의 이미지를 2행 5열로 표시\n",
        "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray') \n",
        "    # plt.imshow()는 (m,n) 형태의 데이터를 입력으로 받기 때문에\n",
        "    # 데이터셋 내의 1열로 펼쳐진 64개의 데이터를 원래의 이미지 형태인 (8,8)로 복원\n",
        "    # cmap은 해당 이미지의 색상을 지정(gray는 흑백으로 출력)\n",
        "    plt.axis('off') # 축을 보이지 않게 해줍니다. \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c79a4f2",
      "metadata": {
        "id": "2c79a4f2",
        "outputId": "b471d8cb-3bdd-4ea6-b570-507c19f6d43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1797,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits_label = digits.target # 각 이미지가 나타내는 숫자를 의미합니다.\n",
        "print(digits_label.shape)\n",
        "digits_label[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3a235c",
      "metadata": {
        "id": "2a3a235c",
        "outputId": "3677f67a-aa75-4fc1-af6e-c9c7d5dd4895"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([178., 182., 177., 183., 181., 182., 181., 179., 174., 180.]),\n",
              " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(digits_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6064bb26",
      "metadata": {
        "id": "6064bb26"
      },
      "source": [
        "라벨의 분포가 고르다 -> imbalance 문제가 없겠구나"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19accf93",
      "metadata": {
        "id": "19accf93"
      },
      "source": [
        "## (4) train, test 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba1128b",
      "metadata": {
        "id": "cba1128b"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
        "                                                    digits_label, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=32) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92598094",
      "metadata": {
        "id": "92598094"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044a1769",
      "metadata": {
        "id": "044a1769",
        "outputId": "41f58066-cc76-49f5-950d-535d40ba06a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Decision tree\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train) \n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "randomforest = RandomForestClassifier(random_state=32)\n",
        "randomforest.fit(X_train, y_train) \n",
        "y_pred_rf = randomforest.predict(X_test) \n",
        "\n",
        "# SVM\n",
        "svm_model = svm.SVC()\n",
        "svm_model.fit(X_train, y_train) \n",
        "y_pred_svm = svm_model.predict(X_test) \n",
        "\n",
        "# SGDClassifer\n",
        "sgd_model = SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train) \n",
        "y_pred_sgd = sgd_model.predict(X_test) \n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train) \n",
        "y_pred_lr = logistic_model.predict(X_test) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db7879a",
      "metadata": {
        "id": "6db7879a",
        "outputId": "690162b3-8bef-4f99-889a-a61be52a76ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desicion Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94        38\n",
            "           1       0.75      0.83      0.79        36\n",
            "           2       0.75      0.84      0.79        32\n",
            "           3       0.92      0.86      0.89        56\n",
            "           4       0.85      0.90      0.88        31\n",
            "           5       0.92      0.97      0.95        36\n",
            "           6       0.97      0.94      0.96        34\n",
            "           7       0.94      0.88      0.91        34\n",
            "           8       0.88      0.78      0.82        27\n",
            "           9       0.79      0.83      0.81        36\n",
            "\n",
            "    accuracy                           0.88       360\n",
            "   macro avg       0.88      0.87      0.87       360\n",
            "weighted avg       0.88      0.88      0.88       360\n",
            "\n",
            "----------------------------\n",
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        38\n",
            "           1       0.97      1.00      0.99        36\n",
            "           2       0.97      1.00      0.98        32\n",
            "           3       1.00      1.00      1.00        56\n",
            "           4       1.00      0.97      0.98        31\n",
            "           5       1.00      0.97      0.99        36\n",
            "           6       1.00      1.00      1.00        34\n",
            "           7       0.97      1.00      0.99        34\n",
            "           8       0.96      0.89      0.92        27\n",
            "           9       0.97      1.00      0.99        36\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "----------------------------\n",
            "SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        38\n",
            "           1       1.00      1.00      1.00        36\n",
            "           2       1.00      1.00      1.00        32\n",
            "           3       1.00      1.00      1.00        56\n",
            "           4       1.00      0.97      0.98        31\n",
            "           5       1.00      0.97      0.99        36\n",
            "           6       1.00      1.00      1.00        34\n",
            "           7       1.00      1.00      1.00        34\n",
            "           8       1.00      1.00      1.00        27\n",
            "           9       0.95      1.00      0.97        36\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "----------------------------\n",
            "Stochastic Gradient Descent\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        38\n",
            "           1       0.97      0.92      0.94        36\n",
            "           2       1.00      0.97      0.98        32\n",
            "           3       0.98      0.98      0.98        56\n",
            "           4       1.00      0.97      0.98        31\n",
            "           5       0.97      0.92      0.94        36\n",
            "           6       1.00      1.00      1.00        34\n",
            "           7       1.00      1.00      1.00        34\n",
            "           8       0.81      0.96      0.88        27\n",
            "           9       0.92      0.97      0.95        36\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.96       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n",
            "----------------------------\n",
            "Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97        38\n",
            "           1       0.95      0.97      0.96        36\n",
            "           2       1.00      0.97      0.98        32\n",
            "           3       1.00      0.98      0.99        56\n",
            "           4       1.00      0.97      0.98        31\n",
            "           5       0.94      0.92      0.93        36\n",
            "           6       1.00      1.00      1.00        34\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       0.96      1.00      0.98        27\n",
            "           9       0.88      1.00      0.94        36\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Desicion Tree')\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print('----------------------------')\n",
        "print('Random Forest')\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print('----------------------------')\n",
        "print('SVM')\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print('----------------------------')\n",
        "print('Stochastic Gradient Descent')\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "print('----------------------------')\n",
        "print('Logistic Regression')\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa426ff2",
      "metadata": {
        "id": "aa426ff2"
      },
      "source": [
        "대체적으로 결과가 잘 나왔다. 글씨를 검출할 때에는 정확도가 더 중요하다고 생각하기 때문에 가장 성능이 안 좋은 모델은 Decision Tree이고 가장 성능이 좋은 모델은 SVM 이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX7tRfVc9OG2"
      },
      "source": [
        "# 프로젝트 (2) load_wine : 와인을 분류해 봅시다"
      ],
      "id": "vX7tRfVc9OG2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7eKOwe89OG3"
      },
      "source": [
        "## (1) 필요한 모듈 import하기"
      ],
      "id": "L7eKOwe89OG3"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cU_HGshv9OG4"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "cU_HGshv9OG4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCGfaHIX9OG4"
      },
      "source": [
        "## (2) 데이터 준비"
      ],
      "id": "zCGfaHIX9OG4"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AmvcIjvm9OG4"
      },
      "outputs": [],
      "source": [
        "wine = load_wine()"
      ],
      "id": "AmvcIjvm9OG4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCupRfvL9OG5"
      },
      "source": [
        "## (3) 데이터 이해하기"
      ],
      "id": "cCupRfvL9OG5"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "outputId": "486934ac-cf3b-49d6-b8a9-d1cbf30bd804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktXYLFu29OG5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "wine.keys()"
      ],
      "id": "ktXYLFu29OG5"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "outputId": "215484ee-ad50-4025-9e9f-d74c7bee121e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozl3S_2a9OG5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "wine_data = wine.data\n",
        "wine_data.shape"
      ],
      "id": "ozl3S_2a9OG5"
    },
    {
      "cell_type": "code",
      "source": [
        "wine_label = wine.target\n",
        "wine_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9gFXRXO_Iry",
        "outputId": "527e2b02-d9e0-43bf-bd1b-7d809a17f1ad"
      },
      "id": "K9gFXRXO_Iry",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "outputId": "4fb99da3-8bb0-4837-d593-bd96101efdd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "zNXZ1oKE9OG5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  label  \n",
              "0                            3.92   1065.0      0  \n",
              "1                            3.40   1050.0      0  \n",
              "2                            3.17   1185.0      0  \n",
              "3                            3.45   1480.0      0  \n",
              "4                            2.93    735.0      0  \n",
              "..                            ...      ...    ...  \n",
              "173                          1.74    740.0      2  \n",
              "174                          1.56    750.0      2  \n",
              "175                          1.56    835.0      2  \n",
              "176                          1.62    840.0      2  \n",
              "177                          1.60    560.0      2  \n",
              "\n",
              "[178 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e76d2c04-a3af-4ec5-a1c2-e67afcfd49d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e76d2c04-a3af-4ec5-a1c2-e67afcfd49d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e76d2c04-a3af-4ec5-a1c2-e67afcfd49d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e76d2c04-a3af-4ec5-a1c2-e67afcfd49d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "wine_df = pd.DataFrame(data=wine_data, columns=wine.feature_names)\n",
        "wine_df['label'] = wine.target\n",
        "wine_df"
      ],
      "id": "zNXZ1oKE9OG5"
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X2hihvqASAR",
        "outputId": "101624c2-60a2-41ee-9e29-183fe4b886fa"
      },
      "id": "3X2hihvqASAR",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alcohol                         0\n",
              "malic_acid                      0\n",
              "ash                             0\n",
              "alcalinity_of_ash               0\n",
              "magnesium                       0\n",
              "total_phenols                   0\n",
              "flavanoids                      0\n",
              "nonflavanoid_phenols            0\n",
              "proanthocyanins                 0\n",
              "color_intensity                 0\n",
              "hue                             0\n",
              "od280/od315_of_diluted_wines    0\n",
              "proline                         0\n",
              "label                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결측지는 없다."
      ],
      "metadata": {
        "id": "IqOBUsVuAYa1"
      },
      "id": "IqOBUsVuAYa1"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "outputId": "b89852c3-1027-469a-eefa-f8907c9570af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "yra6lQAX9OG7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([59.,  0.,  0.,  0.,  0., 71.,  0.,  0.,  0., 48.]),\n",
              " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.hist(wine_df['label'])"
      ],
      "id": "yra6lQAX9OG7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k5iek1V9OG7"
      },
      "source": [
        "라벨의 분포가 고른 편이다다"
      ],
      "id": "0k5iek1V9OG7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh8qnGiv9OG7"
      },
      "source": [
        "## (4) train, test 분리"
      ],
      "id": "Mh8qnGiv9OG7"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aat6FAer9OG7"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
        "                                                    wine_label, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=32) \n"
      ],
      "id": "aat6FAer9OG7"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xqWiWnIL9OG7"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "id": "xqWiWnIL9OG7"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "outputId": "18d21f58-2891-4671-e867-11cd44a78345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ILkvV5L9OG8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Decision tree\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train) \n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "randomforest = RandomForestClassifier(random_state=32)\n",
        "randomforest.fit(X_train, y_train) \n",
        "y_pred_rf = randomforest.predict(X_test) \n",
        "\n",
        "# SVM\n",
        "svm_model = svm.SVC()\n",
        "svm_model.fit(X_train, y_train) \n",
        "y_pred_svm = svm_model.predict(X_test) \n",
        "\n",
        "# SGDClassifer\n",
        "sgd_model = SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train) \n",
        "y_pred_sgd = sgd_model.predict(X_test) \n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train) \n",
        "y_pred_lr = logistic_model.predict(X_test) \n"
      ],
      "id": "6ILkvV5L9OG8"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "outputId": "1b75e0a9-8d89-4184-f8e3-efb6ef105a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIEZtZgh9OG8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desicion Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        16\n",
            "           1       0.89      0.80      0.84        10\n",
            "           2       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.92        36\n",
            "   macro avg       0.91      0.90      0.90        36\n",
            "weighted avg       0.92      0.92      0.91        36\n",
            "\n",
            "----------------------------\n",
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.97      0.97      0.97        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n",
            "----------------------------\n",
            "SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.81      0.87        16\n",
            "           1       0.41      0.90      0.56        10\n",
            "           2       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.45      0.57      0.48        36\n",
            "weighted avg       0.53      0.61      0.54        36\n",
            "\n",
            "----------------------------\n",
            "Stochastic Gradient Descent\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85        16\n",
            "           1       1.00      0.40      0.57        10\n",
            "           2       0.47      0.70      0.56        10\n",
            "\n",
            "    accuracy                           0.69        36\n",
            "   macro avg       0.76      0.66      0.66        36\n",
            "weighted avg       0.77      0.69      0.69        36\n",
            "\n",
            "----------------------------\n",
            "Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        16\n",
            "           1       0.89      0.80      0.84        10\n",
            "           2       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.92        36\n",
            "   macro avg       0.91      0.90      0.90        36\n",
            "weighted avg       0.92      0.92      0.91        36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('Desicion Tree')\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print('----------------------------')\n",
        "print('Random Forest')\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print('----------------------------')\n",
        "print('SVM')\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print('----------------------------')\n",
        "print('Stochastic Gradient Descent')\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "print('----------------------------')\n",
        "print('Logistic Regression')\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ],
      "id": "BIEZtZgh9OG8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ0nh5969OG8"
      },
      "source": [
        "와인분류 역시 정확도가 중요하다고 생각한다. 글씨검출에서 가장 성능이 좋았던 SVM이 가장 성능이 좋지 않은데 기본 SVM을 써서 그렇다고 생각된다. 가장 성능이 좋았던 것은 RandomForest 모델이다."
      ],
      "id": "mZ0nh5969OG8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk1q74IQAC3Q"
      },
      "source": [
        "# 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다"
      ],
      "id": "Rk1q74IQAC3Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4XPz7WGAC3a"
      },
      "source": [
        "## (1) 필요한 모듈 import하기"
      ],
      "id": "W4XPz7WGAC3a"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7u3UNLH6AC3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "7u3UNLH6AC3a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGZhZ0dLAC3b"
      },
      "source": [
        "## (2) 데이터 준비"
      ],
      "id": "LGZhZ0dLAC3b"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OczhUVgpAC3b"
      },
      "outputs": [],
      "source": [
        "bc = load_breast_cancer()"
      ],
      "id": "OczhUVgpAC3b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHtMohZlAC3b"
      },
      "source": [
        "## (3) 데이터 이해하기"
      ],
      "id": "jHtMohZlAC3b"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "outputId": "e72528f4-9918-4f1f-a4e7-afe2f25e1c9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Kvdl_ERAC3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "bc.keys()"
      ],
      "id": "4Kvdl_ERAC3b"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "outputId": "c8fd32b9-53eb-4f61-f250-1d4af33eb0f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qeeyx5BWAC3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "bc_data = bc.data\n",
        "bc_data.shape"
      ],
      "id": "Qeeyx5BWAC3b"
    },
    {
      "cell_type": "code",
      "source": [
        "bc_label = bc.target\n",
        "bc_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a841b4-7156-48db-83e2-eea42132e723",
        "id": "LtyesPFkAC3c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "id": "LtyesPFkAC3c"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "outputId": "4702e3d0-7ace-4c3a-e1d5-30a819fc136e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "JdGJBChsAC3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                   0.07871  ...          17.33           184.60      2019.0   \n",
              "1                   0.05667  ...          23.41           158.80      1956.0   \n",
              "2                   0.05999  ...          25.53           152.50      1709.0   \n",
              "3                   0.09744  ...          26.50            98.87       567.7   \n",
              "4                   0.05883  ...          16.67           152.20      1575.0   \n",
              "..                      ...  ...            ...              ...         ...   \n",
              "564                 0.05623  ...          26.40           166.10      2027.0   \n",
              "565                 0.05533  ...          38.25           155.00      1731.0   \n",
              "566                 0.05648  ...          34.12           126.70      1124.0   \n",
              "567                 0.07016  ...          39.42           184.60      1821.0   \n",
              "568                 0.05884  ...          30.37            59.16       268.6   \n",
              "\n",
              "     worst smoothness  worst compactness  worst concavity  \\\n",
              "0             0.16220            0.66560           0.7119   \n",
              "1             0.12380            0.18660           0.2416   \n",
              "2             0.14440            0.42450           0.4504   \n",
              "3             0.20980            0.86630           0.6869   \n",
              "4             0.13740            0.20500           0.4000   \n",
              "..                ...                ...              ...   \n",
              "564           0.14100            0.21130           0.4107   \n",
              "565           0.11660            0.19220           0.3215   \n",
              "566           0.11390            0.30940           0.3403   \n",
              "567           0.16500            0.86810           0.9387   \n",
              "568           0.08996            0.06444           0.0000   \n",
              "\n",
              "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
              "0                  0.2654          0.4601                  0.11890      0  \n",
              "1                  0.1860          0.2750                  0.08902      0  \n",
              "2                  0.2430          0.3613                  0.08758      0  \n",
              "3                  0.2575          0.6638                  0.17300      0  \n",
              "4                  0.1625          0.2364                  0.07678      0  \n",
              "..                    ...             ...                      ...    ...  \n",
              "564                0.2216          0.2060                  0.07115      0  \n",
              "565                0.1628          0.2572                  0.06637      0  \n",
              "566                0.1418          0.2218                  0.07820      0  \n",
              "567                0.2650          0.4087                  0.12400      0  \n",
              "568                0.0000          0.2871                  0.07039      1  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7763125a-f325-4c1d-9ece-6987ef755ee6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7763125a-f325-4c1d-9ece-6987ef755ee6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7763125a-f325-4c1d-9ece-6987ef755ee6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7763125a-f325-4c1d-9ece-6987ef755ee6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "bc_df = pd.DataFrame(data=bc_data, columns=bc.feature_names)\n",
        "bc_df['label'] = bc.target\n",
        "bc_df"
      ],
      "id": "JdGJBChsAC3c"
    },
    {
      "cell_type": "code",
      "source": [
        "bc_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYsdzlW7AvEy",
        "outputId": "cf404c37-fb52-476b-e1da-141415dfbcb9"
      },
      "id": "vYsdzlW7AvEy",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "label                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결측치 없음"
      ],
      "metadata": {
        "id": "NVUpC2rQAzG4"
      },
      "id": "NVUpC2rQAzG4"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "outputId": "0b6cdc8f-1083-4680-855f-08ebe10863ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "PXCk7Q6MAC3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([212.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 357.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.hist(bc_df['label'])"
      ],
      "id": "PXCk7Q6MAC3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04B7gQ-9AC3c"
      },
      "source": [
        "라벨의 분포 1인경우가 좀더 많다"
      ],
      "id": "04B7gQ-9AC3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAYUklWlAC3c"
      },
      "source": [
        "## (4) train, test 분리"
      ],
      "id": "iAYUklWlAC3c"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FERKI5FgAC3c"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(bc_data, \n",
        "                                                    bc_label, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=32) \n"
      ],
      "id": "FERKI5FgAC3c"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jyWAixkHAC3c"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "id": "jyWAixkHAC3c"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "outputId": "85c3922a-8710-421b-e2f6-f47f3c547e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgtDQGtiAC3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Decision tree\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train) \n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "randomforest = RandomForestClassifier(random_state=32)\n",
        "randomforest.fit(X_train, y_train) \n",
        "y_pred_rf = randomforest.predict(X_test) \n",
        "\n",
        "# SVM\n",
        "svm_model = svm.SVC()\n",
        "svm_model.fit(X_train, y_train) \n",
        "y_pred_svm = svm_model.predict(X_test) \n",
        "\n",
        "# SGDClassifer\n",
        "sgd_model = SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train) \n",
        "y_pred_sgd = sgd_model.predict(X_test) \n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train) \n",
        "y_pred_lr = logistic_model.predict(X_test) \n"
      ],
      "id": "lgtDQGtiAC3c"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "outputId": "ad27a6f7-9969-47e2-fdca-1fa66046fc99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQgdprg1AC3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desicion Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84        44\n",
            "           1       0.90      0.90      0.90        70\n",
            "\n",
            "    accuracy                           0.88       114\n",
            "   macro avg       0.87      0.87      0.87       114\n",
            "weighted avg       0.88      0.88      0.88       114\n",
            "\n",
            "----------------------------\n",
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92        44\n",
            "           1       0.96      0.94      0.95        70\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.93      0.94      0.94       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n",
            "----------------------------\n",
            "SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.73      0.81        44\n",
            "           1       0.85      0.96      0.90        70\n",
            "\n",
            "    accuracy                           0.87       114\n",
            "   macro avg       0.88      0.84      0.85       114\n",
            "weighted avg       0.87      0.87      0.86       114\n",
            "\n",
            "----------------------------\n",
            "Stochastic Gradient Descent\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.93      0.81        44\n",
            "           1       0.95      0.77      0.85        70\n",
            "\n",
            "    accuracy                           0.83       114\n",
            "   macro avg       0.83      0.85      0.83       114\n",
            "weighted avg       0.86      0.83      0.84       114\n",
            "\n",
            "----------------------------\n",
            "Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89        44\n",
            "           1       0.93      0.93      0.93        70\n",
            "\n",
            "    accuracy                           0.91       114\n",
            "   macro avg       0.91      0.91      0.91       114\n",
            "weighted avg       0.91      0.91      0.91       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Desicion Tree')\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print('----------------------------')\n",
        "print('Random Forest')\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print('----------------------------')\n",
        "print('SVM')\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print('----------------------------')\n",
        "print('Stochastic Gradient Descent')\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "print('----------------------------')\n",
        "print('Logistic Regression')\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ],
      "id": "nQgdprg1AC3d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dH_r2fiAC3d"
      },
      "source": [
        "암의 여부를 예측할때에는 실제 양성여부를 놓치면 안되기 때문에 recall을 봐야 한다. recall이 가장 좋은 모델은 0.94로 Random Forest 모델이다."
      ],
      "id": "7dH_r2fiAC3d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}